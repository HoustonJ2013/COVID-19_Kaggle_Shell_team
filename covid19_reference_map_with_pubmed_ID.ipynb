{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install biopython\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the following material as references:\n",
    "- [A references-based atlas of COVID-19 research](https://www.kaggle.com/mmoeller/a-references-based-atlas-of-covid-19-research)\n",
    "- [Gephi tutorial. Publishing interactive graphs online](http://blog.miz.space/tutorial/2020/01/05/gephi-tutorial-sigma-js-plugin-publishing-interactive-graph-online/)\n",
    "\n",
    "You will find the visualization of the [reference map](https://yinsenm.github.io/COVID19/network/) for 20K papers with pubmid and more than 20 citations in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import Entrez\n",
    "from tqdm.notebook import tqdm\n",
    "Entrez.api_key = '5adc258af57a356f01f3a432e4a509504708'\n",
    "Entrez.email = 'yinsenm@gmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'CORD-19-research-challenge' \n",
    "df = pd.read_csv('./%s/metadata.csv' % file_path)\n",
    "df_has_pubmedid = df.dropna(subset=['pubmed_id'])\n",
    "df_has_pubmedid = df_has_pubmedid.drop_duplicates(subset=['pubmed_id'], keep=False)\n",
    "pubmedid_list = [int(id) for id in df_has_pubmedid['pubmed_id'].tolist()]\n",
    "df_has_pubmedid['pubmed_id'] = pubmedid_list\n",
    "jobs_batch = [pubmedid_list[x:(x + 100)] for x in range(0, len(pubmedid_list), 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "refs = []\n",
    "for i, ids in enumerate(tqdm(jobs_batch)):\n",
    "    handle  = Entrez.elink(dbfrom='pubmed', id = ids, linkname='pubmed_pubmed_refs')\n",
    "    results = Entrez.read(handle)\n",
    "    \n",
    "    for res in results:\n",
    "        if res['LinkSetDb'] == []:\n",
    "            pmids = []\n",
    "        else:\n",
    "            pmids = [int(link['Id']) for link in res[\"LinkSetDb\"][0][\"Link\"]]\n",
    "        \n",
    "        refs.append(pmids)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_has_pubmedid['refs'] = refs\n",
    "allrefs = [ref for reflist in df_has_pubmedid['refs'].tolist() for ref in reflist] \n",
    "# calculate cross-references in our data set \n",
    "seen = {}\n",
    "commonrefs = []\n",
    "\n",
    "for x in allrefs:\n",
    "    if x not in seen:\n",
    "        seen[x] = 1\n",
    "    else:\n",
    "        if seen[x] == 1:\n",
    "            commonrefs.append(x)\n",
    "        seen[x] += 1\n",
    "\n",
    "print('There are %i refs that occur more than once.' % len(commonrefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get a list of shared or cross references for each article in our data set \n",
    "# (we throw away the references that are only cited in one article, since they won't help us with the atlas).\n",
    "shared = []\n",
    "cross = {id:1 for id in pubmedid_list}\n",
    "for index, row in df_has_pubmedid.iterrows():\n",
    "    sharerefs = [ref for ref in row['refs'] if seen[ref] > 1 or ref in cross]\n",
    "    shared.append(sharerefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_has_pubmedid[\"sharedrefs\"] = shared\n",
    "df_has_pubmedid['nsharedrefs'] = df_has_pubmedid['sharedrefs'].apply(lambda x : len(x))\n",
    "df_sub_has_pubmedid = df_has_pubmedid[df_has_pubmedid['nsharedrefs'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allids = pubmedid_list\n",
    "nodes = allids + commonrefs\n",
    "node_types = [1 for pub in allids] + [0 for ref in commonrefs]\n",
    "node_titles = [title for title in df['title'].tolist()] + ['' for ref in commonrefs]\n",
    "# node_abstracts = [abstract for abstract in df['abstract'].tolist()] + ['' for ref in commonrefs] \n",
    "nodes_new_paper = [newpaper for newpaper in (df['publish_time'] >= '2020-01-01').astype('int64')] + [0 for ref in commonrefs]\n",
    "nodes_time = [pub_time for pub_time in df['publish_time']] + [\"\" for ref in commonrefs]\n",
    "df_nodes = pd.DataFrame(list(zip(nodes, node_types, node_titles, nodes_new_paper)), columns =['Id', 'Type', 'Label', 'new_paper'])\n",
    "df_nodes.to_csv('full_nodes.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "targets = []\n",
    "for _,row in df_sub_has_pubmedid.iterrows():\n",
    "    source = int(row['pubmed_id'])\n",
    "    for ref in row['sharedrefs']:\n",
    "            target = ref\n",
    "            sources.append(source)\n",
    "            targets.append(target)\n",
    "\n",
    "df_edges = pd.DataFrame(list(zip(sources, targets)), columns =['Source', 'Target'])\n",
    "df_edges.to_csv('full_edges.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
